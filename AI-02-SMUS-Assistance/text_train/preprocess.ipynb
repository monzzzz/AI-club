{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import random  \n",
    "from spacy.lang.en import English\n",
    "from tqdm.auto import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "nlp = English()\n",
    "\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "doc = nlp(\"This is a sentence. This another sentence. I like Elephants\")\n",
    "\n",
    "def assign_properties(pages_and_text, column = \"Page Content\"):\n",
    "    result = []\n",
    "    print(len(pages_and_text[column].tolist()))\n",
    "    for index, page in enumerate(pages_and_text[column].tolist()):\n",
    "        result.append({\"page_number\": index,\n",
    "                               \"page_char_count\": len(page),\n",
    "                               \"page_word_count\": len(page.split(\" \")),\n",
    "                               \"page_sentences\": len(page.split(\".\")),\n",
    "                               \"page_token_count\": len(page)/4, # 1 token ~ 4 characters\n",
    "                                \"text\": page\n",
    "                               })\n",
    "    return result\n",
    "def splitting_into_sentences(pages_and_texts):\n",
    "    for item in tqdm(pages_and_texts):\n",
    "        item[\"sentences\"] = list(nlp(item[\"text\"].sents))\n",
    "        item[\"sentences\"] = [str(sentence) for sentence in item[\"sentences\"]]\n",
    "        item[\"page_space_count_spacy\"] = len(item[\"sentences\"])\n",
    "    return pages_and_texts\n",
    "\n",
    "\n",
    "def split_list(input_list: list, slice_size: int) -> list[list[str]]:\n",
    "    return [input_list[i : i + slice_size] for i in range(0, len(input_list), slice_size)]\n",
    "\n",
    "\n",
    "def chunk(pages_and_texts, num_sentence_chuck_size = 10):\n",
    "    for item in tqdm(pages_and_texts):\n",
    "        item[\"sentence_chunks\"] = split_list(input_list=item[\"sentences\"],\n",
    "                                         slice_size=num_sentence_chuck_size)\n",
    "        item[\"num_chunk\"] = len(item[\"sentence_chunks\"])\n",
    "\n",
    "\n",
    "def join_sentences(pages_and_texts):\n",
    "    pages_and_chunks = []\n",
    "    for item in tqdm(pages_and_texts):\n",
    "        for sentence_chunk in item[\"sentence_chunks\"]:\n",
    "            chunk_dict = {}\n",
    "            chunk_dict[\"page_number\"] = item[\"page number\"]\n",
    "\n",
    "            # Join the sentences, so that the sentence start with capital letter after period\n",
    "            joined_sentence_chunk = \"\".join(sentence_chunk).replace(\" \", \" \").strip()\n",
    "            joined_sentence_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_sentence_chunk)\n",
    "\n",
    "            chunk_dict[\"sentence_chunk\"] = joined_sentence_chunk\n",
    "\n",
    "            chunk_dict[\"chunk_char_count\"] = len(joined_sentence_chunk)\n",
    "            chunk_dict[\"chunk_word_count\"] = len([word for word in joined_sentence_chunk.split(\" \")])\n",
    "            chunk_dict[\"chunk_token_count\"] = len(joined_sentence_chunk)/4\n",
    "\n",
    "            pages_and_chunks.append(chunk_dict)\n",
    "    return pages_and_chunks\n",
    "\n",
    "def get_embeddings(text):\n",
    "    embedding_model = SentenceTransformer(model_name_or_path= \"all-mpnet-base-v2\",\n",
    "                                      device=device)\n",
    "    embeddings = embedding_model.encode(text)\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explore Cookie Settings When you visit any...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Breadcrumb Start Here Thank you for choosin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Breadcrumb  Admissions Publications If you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Breadcrumb Middle School The Middle School ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Schaffter Hall for music (left) is home to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Page Content\n",
       "0      Explore Cookie Settings When you visit any...\n",
       "1     Breadcrumb Start Here Thank you for choosin...\n",
       "2     Breadcrumb  Admissions Publications If you ...\n",
       "3     Breadcrumb Middle School The Middle School ...\n",
       "4     Schaffter Hall for music (left) is home to ..."
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_and_text = []\n",
    "df_smus_website = pd.read_csv(\"smus_page.csv\") \n",
    "df_smus_handbook = pd.read_csv(\"smus_handbook.csv\")\n",
    "for page in df_smus_website[\"Page Content\"]:\n",
    "    pages_and_text.append(page.replace(\"\\n\", \" \"))\n",
    "for page in df_smus_handbook[\"Page Content\"]:\n",
    "    pages_and_text.append(page)\n",
    "\n",
    "df = pd.DataFrame(pages_and_text, columns = [\"Page Content\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\n"
     ]
    }
   ],
   "source": [
    "pages_and_text = assign_properties(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentences</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1496</td>\n",
       "      <td>241</td>\n",
       "      <td>14</td>\n",
       "      <td>374.00</td>\n",
       "      <td>Explore Cookie Settings When you visit any...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3488</td>\n",
       "      <td>567</td>\n",
       "      <td>30</td>\n",
       "      <td>872.00</td>\n",
       "      <td>Breadcrumb Start Here Thank you for choosin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1169</td>\n",
       "      <td>194</td>\n",
       "      <td>10</td>\n",
       "      <td>292.25</td>\n",
       "      <td>Breadcrumb  Admissions Publications If you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2809</td>\n",
       "      <td>462</td>\n",
       "      <td>20</td>\n",
       "      <td>702.25</td>\n",
       "      <td>Breadcrumb Middle School The Middle School ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2167</td>\n",
       "      <td>345</td>\n",
       "      <td>15</td>\n",
       "      <td>541.75</td>\n",
       "      <td>Schaffter Hall for music (left) is home to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>140</td>\n",
       "      <td>5224</td>\n",
       "      <td>863</td>\n",
       "      <td>44</td>\n",
       "      <td>1306.00</td>\n",
       "      <td>St. Michaels University SchoolFamily Handbook ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>141</td>\n",
       "      <td>5093</td>\n",
       "      <td>838</td>\n",
       "      <td>52</td>\n",
       "      <td>1273.25</td>\n",
       "      <td>St. Michaels University SchoolFamily Handbook ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>142</td>\n",
       "      <td>1056</td>\n",
       "      <td>188</td>\n",
       "      <td>13</td>\n",
       "      <td>264.00</td>\n",
       "      <td>St. Michaels University SchoolFamily Handbook ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>143</td>\n",
       "      <td>5416</td>\n",
       "      <td>861</td>\n",
       "      <td>44</td>\n",
       "      <td>1354.00</td>\n",
       "      <td>St. Michaels University SchoolFamily Handbook ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>144</td>\n",
       "      <td>3567</td>\n",
       "      <td>565</td>\n",
       "      <td>33</td>\n",
       "      <td>891.75</td>\n",
       "      <td>St. Michaels University SchoolFamily Handbook ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     page_number  page_char_count  page_word_count  page_sentences  \\\n",
       "0              0             1496              241              14   \n",
       "1              1             3488              567              30   \n",
       "2              2             1169              194              10   \n",
       "3              3             2809              462              20   \n",
       "4              4             2167              345              15   \n",
       "..           ...              ...              ...             ...   \n",
       "140          140             5224              863              44   \n",
       "141          141             5093              838              52   \n",
       "142          142             1056              188              13   \n",
       "143          143             5416              861              44   \n",
       "144          144             3567              565              33   \n",
       "\n",
       "     page_token_count                                               text  \n",
       "0              374.00      Explore Cookie Settings When you visit any...  \n",
       "1              872.00     Breadcrumb Start Here Thank you for choosin...  \n",
       "2              292.25     Breadcrumb  Admissions Publications If you ...  \n",
       "3              702.25     Breadcrumb Middle School The Middle School ...  \n",
       "4              541.75     Schaffter Hall for music (left) is home to ...  \n",
       "..                ...                                                ...  \n",
       "140           1306.00  St. Michaels University SchoolFamily Handbook ...  \n",
       "141           1273.25  St. Michaels University SchoolFamily Handbook ...  \n",
       "142            264.00  St. Michaels University SchoolFamily Handbook ...  \n",
       "143           1354.00  St. Michaels University SchoolFamily Handbook ...  \n",
       "144            891.75  St. Michaels University SchoolFamily Handbook ...  \n",
       "\n",
       "[145 rows x 6 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_text)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/145 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'sents'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pages_and_text \u001b[38;5;241m=\u001b[39m \u001b[43msplitting_into_sentences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpages_and_text\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[88], line 35\u001b[0m, in \u001b[0;36msplitting_into_sentences\u001b[0;34m(pages_and_texts)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplitting_into_sentences\u001b[39m(pages_and_texts):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m tqdm(pages_and_texts):\n\u001b[0;32m---> 35\u001b[0m         item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentences\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(nlp(\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msents\u001b[49m))\n\u001b[1;32m     36\u001b[0m         item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentences\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(sentence) \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentences\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m     37\u001b[0m         item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpage_space_count_spacy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentences\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'sents'"
     ]
    }
   ],
   "source": [
    "pages_and_text = splitting_into_sentences(pages_and_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voice-chat-python3-11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
